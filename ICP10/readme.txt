1. in order to import the cifar10 dataset we had to use keras.datasets.cifar10.load_data() and assign them to the following varibles to indicate the train and test data. (X_train, y_train), (X_test, y_test). Then we asserted the shape of each of the train and test varibles. Next we converting the class vector to a binary class matrix using to_categorical(y_train, 10) after that we normailized the data by dividing the X_train and X_test by 255.

We began to build the sequential model. First we initialized the sequential model using Sequential() then we added the first convolutional layer using model.add(Conv2D(32, (3, 3), padding='same', activation = 'relu', input_shape=X_train.shape[1:])) next we added the 20% drop out layer using model.add(Dropout(0.2)) we added the next convolutional layer after that we added the max pool layer using model.add(MaxPooling2D(pool_size=(2, 2))) we did the same for the next convolutional layer with 64 neurons with drop out and max pooling then another convolutional layer with 128 neurons following the ICP assignment requirement. Finally we added the flatten function to the model model.add(Flatten()) and then created the full connected layers using model.add(Dense(1024, activation = 'relu')) one for 1024 neurons and another for 512 neurons. Finally we added the final fully connected layer with softmax activation. We compiled the model and then fit it.

2. For the next question i repeated the first steps in question 1 to recreate the data and restart the model. To create the functional api we created an input layer using Input(shape=X_train.shape[1:]) after that the first convolutional layer passing it the input layer conv1 = Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer), next the 20% drop out layer drop1 = Dropout(0.2)(conv1) passing it the previous layer. We added another convolutional layer and after it a max pool layer using pool1 = MaxPooling2D(pool_size=(2, 2))(conv2). We continued to follow the ICP assignment requirement. Finally we added the flatten function to the model model.add(Flatten()) and then created the full connected layers using model.add(Dense(1024, activation = 'relu')) one for 1024 neurons and another for 512 neurons. Finally we added the out put fully connected layer with only 10 neurons softmax activation. To create the model we used Model(inputs= input_layer, outputs=output_layer) to pass and intialize the model using the input layer and output layer. We compiled the model and fit it.

To create the ReduceLROnPlateau callbacks we used ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.000001) and for the Early Stopping EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False) and for the ModelCheckpoint  ModelCheckpoint(filepath='modelMC.h5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto') we passed the functions in the fit function using the callbacks=[LRR, ES, MC]

3. we saved the model using model.save('modelFunctionalAPI.h5')

4. We selected the first 4 images to predict using for i in range(4). We showed the images using plt.imshow(X_test[i,:,:]) and plt.show() then used the predict function to return a result  y = model.predict(X_test[[i],:]). We got the following results first is a cat = 4, second a ship = 9, third also a ship = 9, and fouth is an airplane = 1. The model predicted the first 4 correctly.

5. we had to skip number 5 due to personal reasons and not being able to make the deadline
