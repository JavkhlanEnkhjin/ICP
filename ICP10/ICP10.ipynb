{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8n2IkdsIZYja"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "dUBYlstYiK8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data() # Loading cifar10 dataset \n",
        "# changing the shape for X_train, X_test, y_train, y_test\n",
        "assert X_train.shape == (50000, 32, 32, 3)\n",
        "assert X_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "bRJB2FCZZvFT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting class vector to binary class matrix.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "# normalizing the data\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "uTddnLfmaP3Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating sequential model\n",
        "model = Sequential()\n",
        "# adding convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation = 'relu', input_shape=X_train.shape[1:]))\n",
        "# adding 20% drop out\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation = 'relu'))\n",
        "# adding max pool layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# adding the flatten layer to flatten the data\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# adding fully connected layers\n",
        "model.add(Dense(1024, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# adding final fully connected layer with softmax \n",
        "model.add(Dense(10, Activation('softmax')))"
      ],
      "metadata": {
        "id": "4PGfESSKaXZr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "z30S-gXEafvE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "model.fit(X_train, y_train, batch_size=10, epochs=10, validation_split=0.2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwAltaiucmVd",
        "outputId": "76a8e7ba-de39-4058-bd7a-836a228f3f63"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 28s 7ms/step - loss: 1.9873 - accuracy: 0.2662 - val_loss: 1.7364 - val_accuracy: 0.3810\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 1.6095 - accuracy: 0.4109 - val_loss: 1.4592 - val_accuracy: 0.4799\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 22s 5ms/step - loss: 1.4276 - accuracy: 0.4822 - val_loss: 1.3076 - val_accuracy: 0.5306\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 22s 5ms/step - loss: 1.2996 - accuracy: 0.5305 - val_loss: 1.2145 - val_accuracy: 0.5655\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 1.1877 - accuracy: 0.5740 - val_loss: 1.0838 - val_accuracy: 0.6237\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 1.0865 - accuracy: 0.6107 - val_loss: 1.0433 - val_accuracy: 0.6338\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 21s 5ms/step - loss: 0.9981 - accuracy: 0.6439 - val_loss: 0.9288 - val_accuracy: 0.6718\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 22s 5ms/step - loss: 0.9168 - accuracy: 0.6736 - val_loss: 0.9020 - val_accuracy: 0.6816\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 22s 6ms/step - loss: 0.8488 - accuracy: 0.6982 - val_loss: 0.8243 - val_accuracy: 0.7113\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 22s 5ms/step - loss: 0.7886 - accuracy: 0.7211 - val_loss: 0.7822 - val_accuracy: 0.7291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6292e46990>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the loss and accuracy\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T-wVArrbCwL",
        "outputId": "823a9bdc-1333-4ce8-aebe-4d78ea57aaed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.7979 - accuracy: 0.7244\n",
            "Test loss: 0.7979444861412048\n",
            "Test accuracy: 0.724399983882904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Apply the following callbacks to the model:\n"
      ],
      "metadata": {
        "id": "r2MmiYs3iOJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data() # Loading cifar10 dataset\n",
        "# changing the shape for X_train, X_test, y_train, y_test\n",
        "assert X_train.shape == (50000, 32, 32, 3)\n",
        "assert X_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "6WR6dFDppG1X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting class vector to binary class matrix.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "# normalizing the data\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "LzwsD07ipIX2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating functional model\n",
        "input_layer= Input(shape=X_train.shape[1:]) # input layer\n",
        "\n",
        "# adding convolutional layer and passing it the input layer\n",
        "conv1 = Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
        "# adding the 20% dropout layer passing it the layer before\n",
        "drop1 = Dropout(0.2)(conv1)\n",
        "\n",
        "conv2 = Conv2D(32, (3, 3), padding='same', activation='relu')(drop1)\n",
        "# adding max pool layer\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(64, (3, 3), padding='same', activation='relu')(pool1)\n",
        "drop2 = Dropout(0.2)(conv3)\n",
        "\n",
        "conv4 = Conv2D(64, (3, 3), padding='same', activation='relu')(drop2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "conv5 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool2)\n",
        "drop3 = Dropout(0.2)(conv5)\n",
        "\n",
        "conv6 = Conv2D(128, (3, 3), padding='same', activation='relu')(drop3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
        "\n",
        "# adding the flatten layer to flatten the data\n",
        "flat = Flatten()(pool3)\n",
        "drop4 = Dropout(0.2)(flat)\n",
        "\n",
        "# adding fully connected layers\n",
        "hidden_layer=Dense(1024, activation='relu')(drop4) # 1st hidden layer\n",
        "drop5 = Dropout(0.2)(hidden_layer)\n",
        "hidden_layer2=Dense(512, activation='relu')(drop5) # 2nd hidden layer\n",
        "drop6 = Dropout(0.2)(hidden_layer2)\n",
        "\n",
        "# adding final fully connected layer with softmax \n",
        "output_layer=Dense(10, activation='softmax')(drop6) # output layer\n",
        "\n",
        "model = Model(inputs= input_layer, outputs=output_layer) # Initializing and creating the functional api model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) # compiling the model\n",
        "\n",
        "# creating ReduceLROnPlateau callback\n",
        "LRR = ReduceLROnPlateau(monitor='val_acc', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "# creating EarlyStopping callback\n",
        "ES = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
        "# creating ModelCheckpoint callback\n",
        "MC = ModelCheckpoint(filepath='modelMC.h5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto')"
      ],
      "metadata": {
        "id": "njxx3gRZotws"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "history = model.fit(X_train, y_train, batch_size=10, epochs=10, validation_split=0.2, shuffle=True, callbacks=[LRR, ES, MC])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLoXO3k93AoM",
        "outputId": "ca689810-4c46-43c2-c726-783a9e1dd236"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3998/4000 [============================>.] - ETA: 0s - loss: 1.7219 - accuracy: 0.3733WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "4000/4000 [==============================] - 28s 7ms/step - loss: 1.7218 - accuracy: 0.3733 - val_loss: 1.4305 - val_accuracy: 0.4957 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "3993/4000 [============================>.] - ETA: 0s - loss: 1.5443 - accuracy: 0.4666WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "4000/4000 [==============================] - 26s 7ms/step - loss: 1.5444 - accuracy: 0.4666 - val_loss: 1.4207 - val_accuracy: 0.4998 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Save the model. (Store this model will be required for future ICP)."
      ],
      "metadata": {
        "id": "AXFCLHB6iSHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "model.save('modelFunctionalAPI.h5')"
      ],
      "metadata": {
        "id": "_79yJgWv8i2d"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the scores\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PcGqk7JzkeD",
        "outputId": "94def2a9-b51b-4da0-cbe4-0feb0c20107b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 1.4331 - accuracy: 0.4995\n",
            "Test loss: 1.4331207275390625\n",
            "Test accuracy: 0.49950000643730164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Predict the first 4 images of the test data. Then, print the actual label for those 4 images (label means the probability associated with them) to check if the model predicted correctly or not."
      ],
      "metadata": {
        "id": "MmaG2Y9ZiUa6"
      }
    }
  ]
}