{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Follow the instruction below and then report how the performance changed. (Apply all at once)"
      ],
      "metadata": {
        "id": "-LxSypWbcL_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras.optimizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-f0DBhrRDRl",
        "outputId": "7e969302-3985-4c7a-aa91-1666e3fa038d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement keras.optimizers (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for keras.optimizers\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PZaTQNizT9X7"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.constraints import maxnorm\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Input\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# importing dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train.shape[1:]\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "xp = y_test\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# creating sequential model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3),padding='same',input_shape=(X_train.shape[1:]),activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128, (3, 3),padding='same',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3),padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change the previous model into Keras Functional API model."
      ],
      "metadata": {
        "id": "GItQ1ctYuLdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train.shape[1:]\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "xp = y_test\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# creating functional model\n",
        "input_layer = Input(shape=(64,64,3))\n",
        "hidden_layer=Conv2D(32, (3,3), activation='relu')(input_layer)\n",
        "hidden_layer=Dropout(0.2)(hidden_layer)\n",
        "hidden_layer=Conv2D(32,(3,3), activation='relu')(hidden_layer)\n",
        "hidden_layer=MaxPooling2D(pool_size=(2,2))(hidden_layer)\n",
        "hidden_layer=Conv2D(64,(3,3), activation='relu')(hidden_layer)\n",
        "hidden_layer=Dropout(0.2)(hidden_layer)\n",
        "hidden_layer=Conv2D(64,(3,3), activation='relu')(hidden_layer)\n",
        "hidden_layer=MaxPooling2D(pool_size=(2,2))(hidden_layer)\n",
        "hidden_layer=Conv2D(128,(3,3), activation='relu')(hidden_layer)\n",
        "hidden_layer=Dropout(0.2)(hidden_layer)\n",
        "hidden_layer=Conv2D(128,(3,3), activation='relu')(hidden_layer)\n",
        "hidden_layer=MaxPooling2D(pool_size=(2,2))(hidden_layer)\n",
        "hidden_layer = Flatten()(hidden_layer)\n",
        "hidden_layer=Dropout(0.2)(hidden_layer)\n",
        "hidden_layer=Dense(1024, activation='relu')(hidden_layer)\n",
        "hidden_layer=Dropout(0.2)(hidden_layer)\n",
        "hidden_layer=Dense(512, activation='relu')(hidden_layer)\n",
        "hidden_layer=Dropout(0.2)(hidden_layer)\n",
        "output_layer=Dense(10, activation='softmax')(hidden_layer)"
      ],
      "metadata": {
        "id": "sLRNh-zCcEQt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Apply the following callbacks to the model:"
      ],
      "metadata": {
        "id": "PhYef31jyl_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# modelCheckPoint\n",
        "# earlyStopping\n",
        "# ReduceLROnPlateau\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss')\n",
        "]\n",
        "# fitting the model\n",
        "model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=4, callbacks=my_callbacks, batch_size= 32)\n"
      ],
      "metadata": {
        "id": "LzTOrCAHyuJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Save the model. (Store this model will be required for future ICP)."
      ],
      "metadata": {
        "id": "pvN33eahIEfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_icp10')"
      ],
      "metadata": {
        "id": "z-LOtXvWID5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Predict the first 4 images of the test data. Then, print the actual label for those 4 images (label means the probability associated with them) to check if the model predicted correctly or not."
      ],
      "metadata": {
        "id": "908ROhCYIBYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 5):\n",
        "  plt.imshow(X_test[i,:,:])\n",
        "  plt.show()\n",
        "  y = model.predict_classes(X_test[[i],:])\n",
        "  print(\"Actual: \", y_test[i], \"Predicted: \", y[0])\n"
      ],
      "metadata": {
        "id": "BCqjzYJ9HhOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}